# Spark Ecosystem

DataFrame => RDD => Spark Engine => cluster manager

## High Level API / Libraries

They create Dataframe and Datasets

1. Dataframe and Spark SQL
2. Streaming
3. ML lib
4. Graphx

## Low Level APIS

They create a RDD => **Resilient Distributed Dataset**
Which is a Immutable data Structure in Spark that can run in Paralell across a cluster

1. Python
2. Java
3. R
4. Scala => Spark is written in Scala

## Cluster Managers

Spark Engine gives instructions and details for a cluster and cluster manager job is schedule and assign the tasks

1. YARN (yet another resource manager)
2. Mesos
3. K8s
4. standalone
