# Why Apache Spark?

Databases like Oracle, Teradata, exadata, MySQL, etc
store data as **Structured Data** => Tabular Data

but new types of file formats came into picture like csv, Image, Video, JSON/YAML (Semi structured)

## 3V of Big Data

1. Velocity => 1sec, 1hour
2. Variety => Structured, semi structured and Unstructured
3. Volume => 5GB, 10GB, 10 TB

**ETL** => Extract Tranform Load => Data Warehouse
**ELT** => Extract Load Transform => Data Lake

## Issues

1. Storage
2. Processing
   - RAM
   - CPU

### Solutions

1. Monothilic
   - Vertical Scaling
   - Expensive
   - Low Availability
2. Distributed
   - Horizontal Scaling
   - Economical
   - High Availability

First Soltion for Distributed System on a Large Scale is **Apache Hadoop**, **Spark** is the Succesor of it.

Modern Tech doesn't use Hadoop much except for its file system called **Hadoop File System (HDFS)**
